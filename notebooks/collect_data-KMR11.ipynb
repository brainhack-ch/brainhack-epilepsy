{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import pycartool.io\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "import umap\n",
    "from features import *\n",
    "from my_io import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_epiliptic_events(file, sfreq):\n",
    "    df = pd.read_csv(file, sep=\"\\t\", skiprows=1, names=['start', 'stop', 'label'])\n",
    "    df['start_time'] = df['start'] / sfreq\n",
    "    df['stop_time'] = df['stop'] / sfreq\n",
    "    df['duration'] = df['stop_time'] - df['start_time']\n",
    "    df['label'] = [l.split('_')[0] for l in df['label'].values]\n",
    "    annotations = mne.Annotations(df['start_time'], df['duration'], df['label'])\n",
    "    return(annotations)\n",
    "file = fr'V:\\switchdrive\\Brainhack\\KMR11\\d17\\Epileptic_events.mrk'\n",
    "\n",
    "def read_file(fname):\n",
    "    # Read Raw\n",
    "    base_path = os.path.dirname(fname) \n",
    "    base_name = os.path.basename(fname)\n",
    "    raw = pycartool.io.read_sef(fname)\n",
    "    # Read Bads\n",
    "    bad_annotations = mne.Annotations(0, 0, 'null')\n",
    "    for file in os.listdir(base_path):\n",
    "        if file.lower().startswith('bad'):\n",
    "            print(file)\n",
    "            path = os.path.join(base_path, file)\n",
    "            annotations = read_bad_file(path, raw.info['sfreq'])\n",
    "            bad_annotations += annotations\n",
    "    # Read epileptic\n",
    "    epileptic_annotations = mne.Annotations(0, 0, 'null')\n",
    "    for file in os.listdir(base_path):\n",
    "        if file.lower().startswith('epileptic'):\n",
    "            print(file)\n",
    "            path = os.path.join(base_path, file)\n",
    "            annotations = read_epiliptic_events(path, raw.info['sfreq'])\n",
    "            epileptic_annotations += annotations\n",
    "    # Read background\n",
    "    background_annotations = mne.Annotations(0, 0, 'null')\n",
    "    for file in os.listdir(base_path):\n",
    "        if file.lower().endswith('bck.mrk'):\n",
    "            print(file)\n",
    "            path = os.path.join(base_path, file)\n",
    "            annotations = read_background_events_file(path, raw.info['sfreq'])\n",
    "            background_annotations += annotations\n",
    "    annotations = epileptic_annotations + bad_annotations + background_annotations\n",
    "    raw.set_annotations(annotations) \n",
    "    return(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files = list()\n",
    "\n",
    "subject_folder = fr'V:\\switchdrive\\Brainhack\\KMR11'\n",
    "for day_folder in os.listdir(subject_folder):\n",
    "    day_folder = os.path.join(subject_folder, day_folder)\n",
    "    if os.path.isdir(day_folder):\n",
    "        for file in os.listdir(day_folder):\n",
    "            if file.endswith('.sef'):\n",
    "                file = os.path.join(day_folder, file)\n",
    "                files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [(1,30), (200,240)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch_duration = 1\n",
    "all_features = []\n",
    "datas = list()\n",
    "channel = ['e11']\n",
    "for file in files:\n",
    "    try:    \n",
    "        raw = read_file(file)\n",
    "        raw.pick(channel)\n",
    "    except Exception as e:\n",
    "        print(file , e)\n",
    "        continue\n",
    "    day = file.split(\"\\\\\")[4]\n",
    "    subject = file.split(\"\\\\\")[3]\n",
    "    features = []\n",
    "    column_names = []\n",
    "    \n",
    "    events, events_id = mne.events_from_annotations(raw)\n",
    "    for band in bands:\n",
    "        raw_ = raw.copy().filter(band[0], band[1])\n",
    "        epochs = mne.Epochs(raw_, events, event_id=events_id, tmin=0, tmax=epoch_duration, baseline=None,\n",
    "                            on_missing='ignore', event_repeated='drop')\n",
    "        data = epochs.get_data()\n",
    "        activity_features = activity(data)\n",
    "        features.append(activity_features)\n",
    "        column_names += [f'{band}_activity_feature_{i}' for i in range(activity_features.shape[-1])]\n",
    "\n",
    "        mobility_features = mobility(data)\n",
    "        features.append(mobility_features)\n",
    "        column_names += [f'{band}_mobility_feature_{i}' for i in range(mobility_features.shape[-1])]\n",
    "\n",
    "        complexity_features = complexity(data)\n",
    "        features.append(complexity_features)\n",
    "        column_names += [f'{band}_complexity_feature_{i}' for i in range(complexity_features.shape[-1])]\n",
    "\n",
    "        time_features = extract_time_feat(data)\n",
    "        time_features = time_features.reshape((time_features.shape[0],-1))\n",
    "        features.append(time_features)\n",
    "        column_names += [f'{band}_time_feature_{i}' for i in range(time_features.shape[-1])]\n",
    "\n",
    "        frequency_features = extract_freq_feat(data, sfreq=epochs.info['sfreq'])\n",
    "        frequency_features = frequency_features.reshape((frequency_features.shape[0],-1))\n",
    "        features.append(frequency_features)\n",
    "        column_names += [f'{band}_frequency_feature_{i}' for i in range(frequency_features.shape[-1])]\n",
    "\n",
    "        information_features = extract_information_feat(data, sfreq=epochs.info['sfreq'])\n",
    "        information_features = information_features.reshape((information_features.shape[0],-1))\n",
    "        features.append(information_features)\n",
    "        column_names += [f'{band}_information_feature_{i}' for i in range(information_features.shape[-1])]\n",
    "\n",
    "        dwt_features = extract_dwt_feat(data)\n",
    "        dwt_features = dwt_features.reshape((dwt_features.shape[0],-1))\n",
    "        features.append(dwt_features)\n",
    "        column_names += [f'{band}_dwt_feature_{i}' for i in range(dwt_features.shape[-1])]\n",
    "\n",
    "    events_ = np.array([list(events_id.keys())[list(events_id.values()).index(event)] for event in epochs.events[:,2]]).reshape(-1,1)\n",
    "    features.append(events_)\n",
    "    column_names += ['event_name']\n",
    "\n",
    "    ts = epochs.events[:,0].reshape(-1,1) / raw.info['sfreq']\n",
    "    features.append(ts)\n",
    "    column_names += ['start']\n",
    "\n",
    "    days = np.array([day] * len(epochs)).reshape(-1,1)\n",
    "    features.append(days)\n",
    "    column_names += ['day']\n",
    "\n",
    "    subjects = np.array([subject] * len(epochs)).reshape(-1,1)\n",
    "    features.append(subjects)\n",
    "    column_names += ['subject']\n",
    "    \n",
    "    epochs = mne.Epochs(raw, events, event_id=events_id, tmin=0, tmax=1, baseline=None,\n",
    "                            on_missing='ignore', event_repeated='drop')\n",
    "    data = epochs.get_data()\n",
    "    datas.append(data)\n",
    "    \n",
    "    features = np.hstack(features)\n",
    "\n",
    "    all_features.append(features)\n",
    "    \n",
    "df = pd.DataFrame(np.vstack(all_features), columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.vstack(all_features), columns=column_names)\n",
    "df['code'] =  pd.Categorical(df.event_name).codes\n",
    "features = [column for column in df.columns if \"feature\" in column]\n",
    "non_features = [column for column in df.columns if not \"feature\" in column]\n",
    "\n",
    "df[features].to_csv('features.tsv',sep='\\t', index=False, header=False)\n",
    "df[non_features].to_csv('non_features.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = umap.UMAP(n_neighbors=15, n_components=2)\n",
    "data = df[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = fit.fit_transform(data)\n",
    "df['data'] = [data for data in np.vstack(datas)[:,0,:]]\n",
    "df['x1'] = u[:,0].reshape(-1)\n",
    "df['x2'] = u[:,1].reshape(-1)\n",
    "plt.scatter(u[:,0], u[:,1], c=df['code'] , s=1)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import umap.plot \n",
    "umap.plot.output_notebook()\n",
    "\n",
    "\n",
    "p = umap.plot.interactive(fit, labels=df['code'],\n",
    "                          hover_data=df[non_features],\n",
    "                          point_size=4,\n",
    "                          theme='fire',\n",
    "                          background='black',\n",
    "                          #color_key= ['FR', 'HAHF', 'HALF', 'LAHF', 'LALF', 'RP', 'background', 'null'],\n",
    "                          interactive_text_search_columns=True)\n",
    "#\n",
    "umap.plot.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import ColumnDataSource, CustomJS\n",
    "from bokeh.layouts import row\n",
    "from bokeh.palettes import brewer\n",
    "from bokeh.io import  output_notebook\n",
    "output_notebook()\n",
    "\n",
    "colors = brewer[\"Spectral\"][len(df.code.unique())]\n",
    "colormap = {i: colors[i] for i in df.code.unique()}\n",
    "colors = [colormap[x] for x in df.code]\n",
    "df['color'] = colors\n",
    "\n",
    "tooltips = [\n",
    "    (\"day\", \"@day\"),\n",
    "    (\"event\", \"@event_name\"),\n",
    "    (\"subject\", \"@subject\")]\n",
    "\n",
    "s1 = ColumnDataSource(data=df[['x1','x2','day', 'event_name', 'subject', 'data', 'code', 'color']])\n",
    "p1 = figure(width=400, height=400, tools='tap,hover,pan,wheel_zoom,box_zoom,reset', title=\"UMAP\",\n",
    "            tooltips=tooltips)\n",
    "p1.scatter('x1', 'x2', source=s1, color='color')\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "df2['x'] =  np.arange(0,len(df['data'][0]))\n",
    "df2['y'] = df['data'].values[0]\n",
    "s2 = ColumnDataSource(data=df2)\n",
    "p2 = figure(width=400, height=400, title=\"Data\")\n",
    "p2.line('x', 'y', source=s2)\n",
    "\n",
    "s1.selected.js_on_change('indices', CustomJS(args=dict(s1=s1, s2=s2), code=\"\"\"\n",
    "        const inds = cb_obj.indices;\n",
    "        console.log(inds[0]);\n",
    "        const d2 = s2.data;\n",
    "        console.log(s1.data.data);\n",
    "        d2['x'] = []\n",
    "        d2['y'] = []\n",
    "        for (let i = 0; i < d2.index.length; i++) {\n",
    "            d2['x'].push(i)\n",
    "            d2['y'].push(s1.data.data[inds[0]][i])\n",
    "        }\n",
    "        s2.change.emit();\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "\n",
    "#layout = row(p1, p2)\n",
    "show(row(p1, p2))\n",
    "#show(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.palettes import brewer\n",
    "from bokeh.io import  output_notebook\n",
    "output_notebook()\n",
    "\n",
    "colors = brewer[\"Spectral\"][len(df.code.unique())]\n",
    "colormap = {i: colors[i] for i in df.code.unique()}\n",
    "colors = [colormap[x] for x in df.code]\n",
    "df['color'] = colors\n",
    "\n",
    "tooltips = [\n",
    "    (\"day\", \"$day\"),\n",
    "    (\"event\", \"$event_name\"),\n",
    "    (\"subject\", \"$subject\")]\n",
    "\n",
    "s1 = ColumnDataSource(data=df[['x1','x2','day', 'event_name', 'subject', 'data', 'code', 'color']])\n",
    "p1 = figure(width=400, height=400, tools='tap,hover,pan,wheel_zoom,box_zoom,reset', title=\"UMAP\",\n",
    "            tooltips=tooltips)\n",
    "p1.scatter('x1', 'x2', source=s1)\n",
    "show(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "day = 23\n",
    "subject = 11\n",
    "start = 1656\n",
    "raw = read_file(fr'V:\\\\switchdrive\\\\Brainhack\\\\KMR{subject}\\\\d{day}\\\\KMR{subject}_d{day}_Raw_DS.Avg_ref.sef')\n",
    "\n",
    "for band in bands:\n",
    "    raw_ = raw.copy().filter(band[0], band[1])\n",
    "    raw_.plot(scalings='auto', start=start, decim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "cbce18f089dd3a859c694fc9cb3e5910840ad7a47cd5eed605806d0498c40634"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
